import numpy as np
import os
from random import shuffle
from tqdm import tqdm
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator


TRAIN_DIR = 'C:/Users/Evan/Desktop/Data for ML/train'
TEST_DIR = 'C:/Users/Evan/Desktop/Data for ML/test'

IMG_SIZE = 50
LR = 1e-3


MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR,'6conv-basic')


def label_img(img):
    # -3 means dog.93.png
    word_label = img.split('.')[-3]
    if word_label == 'cat':
        return [1,0]
    elif word_label == 'dog':
        return [0,1]

def train_cats(img):
    word_label = img.split('.')[-3]
    if word_label == 'cat':
        return os.path.join(TRAIN_DIR, 'cats')
def train_dogs(img):
    word_label = img.split('.')[-3]
    if word_label == 'dog':
        return os.path.join(TRAIN_DIR, 'dogs')


def num_cats_tr():
         len(os.listdir(train_cats))
  
def num_dogs_tr():
         len(os.listdir(train_dogs))

def total_train():
        num_cats_tr + num_dogs_tr

def total_test():
        len(os.listdir(TEST_DIR))
    
def create_train_data():
    training_data = []
    for img in tqdm(os.listdir(TRAIN_DIR)):
        label = label_img(img)
        path = os.path.join(TRAIN_DIR,img)
        img = cv2.resize(cv2.impread(path,cv2.IMPREAD_GRAYSCALE),(IMG_SIZE,IMG_SIZE))
        training_data.append([np.array(img),np.array(label)])
    shuffle(training_data)
    np.save('train_data.npy',training_data)
    return training_data



def process_test_data():
    testing_data = []
    for img in tqdm(os.listdir(TEST_DIR)):
        path = os.path.join(TEST_DIR,img)
        img_num = img.split('.')[0]
        img = cv2.resize(cv2.impread(path,cv2.IMPREAD_GRAYSCALE),(IMG_SIZE,IMG_SIZE))
        testing_data.append([np.array(img),img_num])

    np.save('test_data.npy',testing_data)
    return testing_data


train_data = create_train_data
test_data = process_test_data

BATCH_SIZE = 32

train_image_generator = ImageDataGenerator(
    rescale=1./255)

test_image_generator = ImageDataGenerator(
    rescale=1./255)

train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                           directory=TRAIN_DIR,
                                                           shuffle=True,
                                                           target_size=(IMG_SIZE, IMG_SIZE),
                                                           class_mode='binary')

test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                           directory=TEST_DIR,
                                                           shuffle=False,
                                                           target_size=(IMG_SIZE, IMG_SIZE),
                                                           class_mode='binary')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),

    tf.keras.layers.Dense(2, activation='softmax')

    ])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

EPOCHS = 100
history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
    epochs=EPOCHS,
    testing_data = test_data_gen,
    testing_steps=int(np.ceil(total_test / float(BATCH_SIZE)))
    )


